\chapter{UAV Management Platform}
\label{chapter:uav-management-framework}

\section{Architecture}
\label{sec:architecture}
For the Autonomous UAV platform we have used an architecture based on multiple
agents that communicate with the \textit{Mission Supervisor} via a CAN.
The CAN will also be able to route messages
to other CAN buses. 

The testing architecture can be seen in  \labelindexref{Figure}{img:platform-architecture}.

\fig[scale=0.5]{src/img/platform-architecture.png}{img:platform-architecture}
{Autonomous UAV testing framework.}
\newpage
In \labelindexref{Figure}{img:platform-architecture}, the components are as
follows:
\begin{description}
\item [FG\textsubscript{1..n}\abbrev{FG}{Flight Gear Instance}] FlightGear Flight Simulator. Simulator responsible
flying a single drone.
\item [FGMS\abbrev{FGMS}{FlightGear Multi-Player Server}] \hfill \\ FlightGear Multi-Player Server. It has the role of broadcasting
information about UAVs between multiple instances of \textit{FlightGear Flight Simulator}
\item [RPI\textsubscript{1..n}\abbrev{RPI}{Raspberry PI}] \hfill \\Raspberry PI Computer. Runs the \textit{Mission Supervisor}.
\item [CAN\textsubscript{1..n}\abbrev{CAN}{Controller Area Network}] \hfill \\ CAN Interface Simulator. Mimics the behavior of 
a CAN bus and sends messages between a \textit{Flight Gear Flight Simulator} 
instance a \textit{Raspberry PI Mission Supervisor}
\item [R] \hfill \\ CAN Interface Router. Broadcasts the telemetry position from one
\textit{Flight Gear Flight Simulator} instance to the rest of the instances.
\item [QGC\abbrev{QGC}{QGroundControl}] \hfill \\ QGroundControl. Ground Control Software responsible of collecting data
from all the UAVs and plotting them on a map for visualizing the flight path.
\end{description}

In the Autonomous UAV project, QGC also has the role to prepare the mission plan
that will be uploaded on each UAV.

The \textit {Mission Supervisor} architecture is depicted in  \labelindexref
{Figure}{img:rpi-architecture}.

\fig[scale=0.5]{src/img/rpi-architecture.png}{img:rpi-architecture}{Mission 
Supervisor Architecture.}
\newpage
In \labelindexref{Figure}{img:rpi-architecture}, the components are as
follows:
\begin{description}
\item [IO Manger] \hfill \\
Input-Output module responsible for communicating with the UAV via the CAN bus 
and passing the date to the flight modules.
\item [Clips Engine] \hfill \\
Rules based decision engine.
\item [UAV State Manger] Module responsible for monitoring the state of the UAV.
The date that it monitors includes heading, speed,  position etc.
\item [Navigation] \hfill \\
Module responsible for deciding the flight path
\item [Collision Avoidance] \hfill \\
Reactive module responsible for detecting and avoiding in flight collisions.
\item [Formation Flight] \hfill \\
Module responsible for coordinating a fleet of UAVs for maintaining a coherent
flight formation.
\end{description}

This thesis handles the \project module that will be integrated with the other
modules developed in the Autonomous UAV project to obtain an automated pilot
that will be used for controlling the Hirrus UAV \cite{hirrus}.

The \textit{UAV State Manager Module} is responsible for maintaining correct
data about the state of the aircraft (eg: fuel level, evasive maneuvers, equilibrium
sate). If a state of incoherence is detected by the state manager it will notify
the adjacent modules and request the necessary modification of the parameters
so that the aircraft is return to a stable and safe state. The general flight
path is generated and modified for by the \textit{Navigation Module}. The desired
mission goals are resolved by this module and a generic flight path is generated.
This module acts similar to a GPS system that indicates the necessary routes 
to follow to arrive at a destination. In the situation that the aircraft is 
unable to follow these indications, the module is responsible to provide
an alternate indication by reconfiguring the flight path. The 
rules based \textit{Clips Engine} is responsible for providing the flight 
suggestions in an event driven style. For example, if the parameters indicate
a possible collision, the engine generates an event signaling the \textit{
  Collision Avoidance Module} that evasive maneuvers are needed. The \textit{
Collision Avoidance Module} indicates the necessary maneuvers to avoid the
intersection of two drones or a drone with an inanimate object. 

The \textit{Formation Flight Module} computes the necessary heading and altitude
a drone has to maintain so that it stays in formation. The combined outputs 
of the \textit{Formation Flight Module} and \textit{Collision Avoidance} module
can be obtained in two manners. One is implemented using priorities, where the
output from one module is executed before the output of the other one. The second
way can be obtained by merging the two outputs in a arithmetical way with different
percentages for each.

\section{Functionalities}
\label{sec:functionalities}

The platform has the roles of:
\begin{enumerate}
\item Setting the flight mission objectives.
\item Selecting the flight area.
\item Selecting the aircraft types.
\item Configuring the sensors for each aircraft.
\item Based on the settings from above, generate and upload a configuration file
to each aircraft.
\item After the airplanes are airborne, they will be supervised using the 
ground control module.
\item To control the airplanes in an autonomous way, where human intervention is
needed at least as possible.
\item Override the \textit{Mission Supervisor} or completely deactivate it, 
switching to a RC Controlled state.
\end{enumerate}

For using the platform a will act as described below.

Using the custom widget built in QGroundControl will configure the flight objectives, 
selecting the number of aircrafts that will be launched, the type of sensor that
will be equipped on each drone. Also the user has to create a flight path for 
each UAV if they are not flying in a tight formation. If the drone will fly in 
a close ranged formation, the user has to designate a leader and create a flight
plan for him, the other UAVs will follow his path. In the case of close ranged 
formation, the user will specify the kind of formation that will be used (eg: 
  V formation, Line formation). After the mission details have been set, the user
will generate a configuration file that contains a rule based language that
is close to the natural language and that will be interpreted by a CLIPS engine.
The configuration file will be uploaded on the UAVs. When the drones are ready
they are airborne and the autonomous pilot will guide to follow the mission.
From this point their mission can be overseen using QGroundControl where their
flight path is displayed on the map and where their telemetry is also displayed.
In case of necessity, the user will send additional commands to the drones, or
it will will switch the drone to RC mode and return it to base.

