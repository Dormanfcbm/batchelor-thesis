\chapter{Software Management Platform for UAVs}
\label{chapter:uav-management-framework}

\section{Platform Architecture}
\label{sec:architecture}
For the Autonomous UAV platform we proposed an architecture based on multiple
agents that communicate with the \textit{Mission Supervisor} via a CAN buss.
The CAN buss will also be able to route messages to other CAN buses. 

The testing architecture can be seen in  \labelindexref{Figure}{img:platform-architecture}.

\fig[scale=0.5]{src/img/platform-architecture.png}{img:platform-architecture}
{Autonomous UAV testing framework.}
\newpage
In \labelindexref{Figure}{img:platform-architecture}, the components are as
follows:
\begin{description}
\item [FG\textsubscript{1..n}\abbrev{FG}{Flight Gear Instance}] FlightGear Flight Simulator. \hfill \\
Software Simulator able to fly a single drone in a dedicated environment
Simulator responsible
flying a single drone.
\item [FGMS\abbrev{FGMS}{FlightGear Multi-Player Server}] \hfill \\ FlightGear Multi-Player Server. 
Multi-player server used for displaying multiple UAVs in the same FGFS flying environment.
\item [RPI\textsubscript{1..n}\abbrev{RPI}{Raspberry PI}] \hfill \\Raspberry PI Computer. 
Mini computer that runs the artificial intelligence software agent responsible for
controlling each UAV.
\item [CAN\textsubscript{1..n}\abbrev{CAN}{Controller Area Network}] \hfill \\ CAN Interface Simulator.
Communication module simulating a CAN bus relaying messages between the software agent and FGFS
\item [R] \hfill \\ CAN Interface Router. Telemetry router used for notifying each
UAV of the telemetry data of the others UAVs.
\item [QGC\abbrev{QGC}{QGroundControl}] \hfill \\ QGroundControl. Ground Control Software responsible of
displaying the flight path of the by plotting the position of each 
UAV based on the messages received from FGFS
\end{description}

In the Autonomous UAV project, QGC also has the role to prepare the mission plan
that will be uploaded on each UAV.

The \textit {Mission Supervisor} architecture is depicted in  \labelindexref
{Figure}{img:rpi-architecture}.

\fig[scale=0.5]{src/img/rpi-architecture.png}{img:rpi-architecture}{Mission 
Supervisor Architecture.}
\newpage
In \labelindexref{Figure}{img:rpi-architecture}, the components are as
follows:
\begin{description}
\item [IO Manger] \hfill \\
Input-Output module responsible for communicating with the UAV via the CAN bus 
and passing the date to the flight modules.
\item [Clips Engine] \hfill \\
Rules based decision engine.
\item [UAV State Manager] Module responsible for monitoring the state of the UAV.
The monitored data by the UAV State Manager is represented by the values
of the speed, latitude, longitude, altitude and flight direction
\item [Navigation] \hfill \\
Module responsible for deciding the flight path
\item [Collision Avoidance] \hfill \\
Reactive module responsible for detecting and avoiding in flight collisions.
\item [Formation Flight] \hfill \\
Module used for the coordination of a swarm of drones to enter and fly in
a coherent UAV formation.
\end{description}

This thesis handles the \project module that will be integrated with the other
modules developed in the Autonomous UAV project to obtain an automated pilot
that will be used for controlling the Hirrus UAV \cite{hirrus}.

The \textit{UAV State Manager Module} is responsible for maintaining correct
data about the state of the aircraft (eg: fuel level, evasive maneuvers, equilibrium
sate). If a state of incoherence is detected by the state manager it will notify
the adjacent modules and request the necessary modification of the parameters
so that the aircraft is returned to a stable and safe state. The general flight
path is generated and modified by the \textit{Navigation Module}. The desired
mission goals are resolved by this module and a generic flight path is generated.
This module is similar to a GPS system that indicates the necessary routes 
to follow in order to arrive at a destination. In the situation that the aircraft is 
unable to follow these indications, the module will provide
an alternate indication by reconfiguring the flight path. The 
rules based \textit{Clips Engine} is responsible for providing the flight 
suggestions in an event driven style. For example, if the parameters indicate
a possible collision, the engine generates an event signaling the \textit{
  Collision Avoidance Module} that evasive maneuvers are needed. The \textit{
Collision Avoidance Module} indicates the necessary maneuvers to avoid the
intersection of two drones or a drone with an inanimate object. 

The \textit{Formation Flight Module} computes the necessary heading and altitude
a drone has to maintain so that it stays in formation. The combined outputs 
of the \textit{Formation Flight Module} and \textit{Collision Avoidance} module
can be obtained in two manners. One is implemented using priorities, where the
output from one module is executed before the output of the other one. The second
way can be obtained by merging the two outputs in a arithmetical way with different
percentages for each.

\section{Functionalities}
\label{sec:functionalities}

The platform is designated to have the following functionalities:
\begin{enumerate}
\item Configuring the flight mission objectives.
\item Configuring the desired area to be flown over.
\item Configuring the sensors for each aircraft.
\item Generation and auto deployment of a configuration file obtained from the
settings configured above.
\item Flying the airplanes in an self-driving mode with human intervention reduced
to a minimum.
\item Intervene in the autopilot mission by either deactivating the AI software
agent or by reconfiguring the mission
\end{enumerate}

When using the platform,  the user will perform the actions described below.

Using the custom widget built in QGroundControl which will configure the flight objectives, 
how many drones will be launched, witch kind of sensors will be carried .
Also the user has to create a flight path for 
each UAV if they are not flying in a tight formation. If the drone will fly in 
a close ranged formation, the user has to designate a leader and create a flight
plan for him, the other UAVs will follow his path. In the case of close ranged 
formation, the user will specify the kind of formation that will be used (eg: 
  V formation, Line formation). After the mission details have been set, the user
will generate a configuration file that contains a rule based configuration, designed
 to be as close as possible to natural language, and that will be parsed using
 an inference engine based on CLIPS.
On the drones the configuration arrives via an auto deploy mechanism. When the drones are ready
they are airborne and the autonomous pilot module will guide the aircraft to follow the mission.
From this point their mission can be overseen using QGroundControl where their
flight path is displayed on the map and where their telemetry is also displayed.
In case of necessity, the user will send additional commands to the drones, or
it will will switch the drone to RC mode and return it to base.

