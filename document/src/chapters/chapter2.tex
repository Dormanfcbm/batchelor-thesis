\chapter{Related Work}
\label{chapter:related-work}

A large number of articles describe the work done to solve the problem of autopilots for
UAV swarms, as well as communication and coordinate systems. In the following paragraphs 
we will describe the main ideas and trade-offs for each described solution.

The autopilot problem is well covered in the literature and from real life practice
it is considered that the best approach is a stratified architecture. Each layer
is responsible for receiving commands from the one above it, deciding if the
the command would put the UAV in a state of imbalance, or danger in general, and
forwarding the command to the layer below. If a possible imbalance state is detected
the layer either discards the received command and does not send any command to 
the next layer, or it tweaks the command so that a incoherent state would not
be induced.

The architecture proposed by Borges de Sousa et. al \cite{pivant} would have
the following layers:

\begin{description}
\item[Platform] \hfill \\ The UAV vehicle with all the hardware
\item[Maneuverer controller] \hfill \\ Controller that decides what hardware action is 
executed (roll, pitch, yaw)
\item[Vehicle supervisor] \hfill \\ Basic autopilot capable to make simple decisions 
(setting the target speed, setting the heading)
\item[Mission supervisor] \hfill \\ Artificial Intelligence System that plans the mission
based on a template and the rest of the drones. It forwards the commands to the
Vehicle Supervisor for validation
\item[External controller] \hfill \\ Human factor that can interfere between the Mission
Supervisor and Vehicle Supervisor to override or even deactivate the first one.
\end{description}

The architecture imagined by Borges de Souse can be seen in \labelindexref{Figure}{img:vechicle-arhitecture}.

\fig[scale=0.5]{src/img/vechicle-control-arhitecture.png}{img:vechicle-arhitecture}
{Vehicle Control Architecture.}

\newpage
The advantages provided by this kind of architecture is the separation of
concerns for each level and the fact that the repair in case of failure can be
easily detected and fixed. The only draw-back of this approach is the fact
that in the case of poor implementation it could introduce a latency in communication, 
loosing the possibility of having a real time system.

The autopilot system presented in this thesis is similar to the one described
above because the Hirrus drone \cite{hirrus} provided by TNI already contains
a maneuver controller, vehicle supervisor and an external controller. Thus the
system described in these thesis would act as a mission supervisor.

In the terms of UAV teams, Mark D. Richards and his colleagues \cite{cooperative}
identify two main groups of strategies. The first one, called \textbf{Behavior-based
Control Systems}, uses a mesh of interacting high-level behaviors to perform a 
task. The second one, \textbf{Deliberative System}, acts by creating a specific
flight path for each individual UAV to follow. This second behavior is a 
generalization of the search path optimization that  Ablavsky proposes in 
  \cite{path-optimization}. Ablavsky approaches the problem by applying the 
following steps:

\begin{enumerate}
\item Restrict the search area based on the mobility of the target.
\item Divide the search area in to the smallest number of sub-regions keeping in
mind the constrains of the aircraft.
\item Determine a search pattern for each sub-region with the property of assuring
full coverage with a minimized path length.
\item Combine the individual results into an optimal global path.
\end{enumerate}

The deliberative approach used by Richards is based on dividing an area for 
each UAV and generating inside the designated zone a flight path to be followed.
For achieving some degree of flexibility, Richards opted not to use an adaptive
replanning where a central controller computes a specific flight path for each
agent and and then broadcasts it to the team. The drawbacks of this approach are
represented by the fact that there would still be a single point of failure and
the fact that by the time the plan is sent to the UAV it may already be 
deprecated. The approach that was used was a reactive one. The initial path
is computed and if a hostile condition is encountered each UAV has to determine
a way to exit that state. By these means Richards managed to sweep an area
that is divided in sub-zones with different degrees of danger and even a no fly
zone. The reactive behavior was useful to avoid collision with a friendly unit
or to escape a danger zone.

Although Richards proposal uses a long range unsynchronized flight team, in this
thesis we used a similar approach for obtaining a synchronized formation.

Gaudiano and his team researched the possibility to explore a zone based on the 
strategies used by schools of fish, flocks of birds and swarms of insects. 
The research they published in \cite{bugs} and \cite{c2-paradigm} is based on 
mimicking the pheromones left behind by the swarms of insects. To be able to 
replicate the insects behavior, Gaudiano assumed that each UAV is aware of the 
terrain geometry through a sensor that provides a forward cone of vision
able to detect elevation and distance. Each UAV also has a sensor to detect the other UAVs 
in a given sphere, positioned using GPS-like coordinates and has a sensor
that mimics the pheromone detection. The later sensor detects, within a rectangular
region centered on the UAV, the coverage of the current cell. In their simulation
they have used a global communication system that was able to assure data flow
between each two UAVs. The strategy to control the UAVs is implemented in a 
decentralized way where each UAV can decide what action to execute. Gaudiano 
tested 5 strategies to explore an area:

\begin{description}
\item[Baseline] \hfill \\ Each UAV starts with a different heading, flies in a straight line
until the area limit is reached and then turns so that it doesn't leave the area.
\item[Random] \hfill \\ Is similar to the baseline implementation but at each time step, 
the UAV will change it's heading by a small random angle.
\item[Repulsion] \hfill \\ An UAV can detect the other UAVs on a given radius and it changes
it's heading so that they do not intersect.
\item[Pheromone] \hfill \\ Each UAV is able to detect the already explored cells and changes it's
heading so that it heads in the direction of unexplored cells.
\item[Global]  \hfill \\ The area is divided in smaller regions ana an UAV knows 
how many UAVs are in one region and based on that it decides what region to explore.
\end{description}

Based on their experiments they have discovered that the most efficient way to
obtain a higher coverage is the pheromone strategy. Compared to the repulsion 
strategy that obtained a 44\% coverage the the pheromone strategy obtained a 
60\%. These coverages were obtained using 10 UAVs. The same experiments showed
that scaling to larger UAV swarms presents a drawback represented by the fact
that although the coverage efficiency increases with the number of UAVs, 
their relative efficiency decreases. While on a very large area 10 UAVs would
cover 6\%, 110 UAVs would cover only 33\%.

In contrast with the approaches form above, Nowak centered his research on 
creating a self organized swarm. To achieve this he created a three-tiered architecture
for a SO\abbrev{SO}{Self Organized} System Model that separates the implementation 
details from the real world agents behavior. This architecture (as presented in
  \cite{so}) can be seen in  \labelindexref{Figure}{img:tireso}.

\fig[scale=0.7]{src/img/tireso.png}{img:tireso}{Three tier SO architecture.}
\newpage

The behavior of many cooperative agents in the same way is a behavior that
has been studied in detail by many researchers. Reynolds proposed in 1987, 
three fundamental rules for swarming: \cite{swarmrules}

\begin{description}
\item [Separation] \hfill \\ The UAV must steer away from the nearest neighbors to avoid crowding.
\item [Cohesion] \hfill \\ The UAV must steer towards the average position of its neighbors.
\item [Alignment] \hfill \\ The UAV must steer towards an average heading of the neighbors.
\end{description}

A visual representation can be seen in \labelindexref{Figure}{img:3rules}

\fig[scale=0.2]{src/img/fundamental-swarming-rules.png}{img:3rules}{Fundamental Swarming Rules.}

Based on Reynolds rules, Nowak implemented, in SWARMFARE 10, rules for a coherent
formation flight \cite{so}:

\begin{description}
\item [Flat Align] \hfill \\ vector align neighbors
\item [Target Orbit] \hfill \\ orbit target at safe distance
\item [Cluster Range Towards] \hfill \\ cohesion
\item [Cluster Range Away] \hfill \\ separation
\item [Attract] \hfill \\ towards center of mass of all targets
\item [Weighted Attract] \hfill \\ towards closest target
\item [Target Repel] \hfill \\ repel if within 90\% of UAV sensor range
\item [Weighted Target Repel] \hfill \\ repulsion based on proximity to target
\item [Evade] \hfill \\ Apriori collision detection and avoidance
\item [Obstacle Avoidance] \hfill \\ Real time obstacle avoidance
\end{description}

The difference between the previous approaches and Nowak's is that the later
considers that at no point an agent will give commands such as "Slow down", "Turn" or
"Dive". Each UAV is responsible for computing what action to execute based on 
a minimal set of date received from the other UAVs. A possible set of data
is formed from:
\begin{itemize}
\item GPS coordinates
\item altitude
\item speed
\item heading
\end{itemize}

To test the SWARMFARE framework, Nowak opted to paralyze the computation
using a Master-Slave architecture. The resulting parallel time calculation
results from the equation:

\begin{equation}
T_{p} = k (t_{s}+t_{w}m)(p-1) + \frac{n^{ck}}{p}
\qquad\parbox{4.0cm}{\footnotesize$\begin{aligned} 
 k &= \text{ number of generations}
  \\[-1.0ex] t_{s} &= \text{ setup time}
  \\[-1.0ex] t_{w} &= \text{ transfer time}
  \\[-1.0ex] p &= \text{ number of processors}
  \\[-1.0ex] n &= \text{ number in population}
  \\[-1.0ex] p &= \text{ constant defining the variable}
  \\[-1.0ex] n^ck &= \text{ linear calculation time}
\end{aligned}$}
\label{eqn: nowak-paralel-time}
\end{equation}

The time obtained by using a initial population of 2 per node
is 540 minutes for one node and 80 minutes for 16 nodes.

The SWARMFARE is a work in progress and the trade-offs that could appear only
from the implementation of the 10 rules. 

The Autonomous UAV project proposes to implement an autopilot that integrates
the behaviors depicted by the rules proposed by Nowak. The formation flight module
implement in this thesis will integrate with the obstacle avoidance module and
surveillance modules developed by my colleagues.

Based on the communication mode, there are two main methods for implementing 
UAV formation flight: coordinated or cooperative. Bourgault et. al. depict the
difference between the two modes in \cite{bayesian}. According to them
in coordinated approach each agent decides what actions to execute based
on the current knowledge of the world but there is no possibility that the actions
of an agent to influence the decisions of another. The cooperative mode has the
advantage that agents negotiate what actions to execute, thus obtaining a 
global optimal solution. On the other side the coordinated mode obtains a 
suboptimal solution, but has the advantage that the individual computation 
time does not increase with the number of agents.

For a close range formation both these modes are necessary. The coordinated
mode is useful for computing the position in the formation for each aircraft 
and the cooperative mode is useful for a collision avoidance module. 
Similar to Bourgault, the solution presented in this thesis is
a coordinated mode with a one-step look-ahead.

For obtaining obstacle avoidance it's necessary to have a reactive system combined
with a cooperative decision making algorithm. Call et. al tried to implement
such a system by obtaining data from video cameras. The cameras are preferred
because they are passive, lightweight, simple and inexpensive sensors. The
drawback for these sensors is represented by the fact that under low-visibility, 
such as fog, smoke or night, have reduced efficiency. Also the processing of the
information could have high computation time. In the research paper \cite{tracking}, 
they have managed to obtain three dimensional data from cameras either by using
a stereo vision system or by using multiple frames from one camera. They have
found out that the relative position of an object can be obtained with an
enough amount of information by using a single camera and multiple frames. The 
main problem with detecting obstacles is that most of the existing algorithms 
are based on detecting a texture variation or the detection of corners. Problems
in detecting obstacles appear when the objects are described by parallel lines 
with no visible endpoint or have no texture. Another case when the algorithm could
fail is when the obstacles have reflective glass surfaces.

The results published in \cite{tracking} can be seen in \labelindexref{Figure}{img:tracking}

\fig[scale=1]{src/img/tracking.png}{img:tracking}{Overhead view of the flight path
of the UAV as it avoids an obstacle indicated by the black box.}
\newpage

When using cameras to detect obstacles, the angular velocity of the gyroscope often
has a large amount of noise, mostly because of the yaw angle or wind. Thus
the angular velocity has to be estimated using another type of on-board sensor. 

\cite{vision-based} approaches this problem by applying the following steps:
\begin{enumerate}
\item Classify the image blocks in structural and non-structural blocks
\item Find multiple "best" motion vectors instead of a single one and chose the
optimal one using a predefined metric
\item Using the data about structural motion, estimate the camera motion to reduce
uncertainty in the motion for non-structural blocks.
\end{enumerate}

In the same article \cite{vision-based} uses the following two formulas to
compensate the motion noise of the camera:


\begin{equation}
m(O_{B}, r) = \frac{1}{ | C(O_{B}, r |}\oint_{C(O_{B}, r)}I_{t}(x, y)dxdy, 0 < r \leq R
  \label{eqn:intensity-profile-pixel}s
\end{equation}

Where: 
\begin {itemize}
  \item {O}\textsubscript{B} = (X\textsubscript{B}, Y\textsubscript{B}) center of block B
  \item C(O\textsubscript{B} , r) = circle center in O\textsubscript{B}  with radius r
  \item R = maximum radius to search
  \item m(O\textsubscript{B} , r) = intensity profile of pixel O\textsubscript{B}  or block B
\end {itemize}

 
\begin{equation}
d_{1}(A, B) = \min_{1 - \delta \leq  \lambda \leq 1 + \delta} \max_{0 \leq r \leq \frac{R}{\lambda}} | m(O_{A}, \lambda r) - m(O_{B}, r) |
\label{eqn:distance-block}
\end{equation}

Where: 
\begin {itemize}
  \item $\lambda$ = scaling factor
  \item $[1 - \delta, 1 + \delta]$  = search range for $\lambda$
\end {itemize}

From \labelindexref{Equation}{eqn:intensity-profile-pixel} and 
\labelindexref{Equation}{eqn:distance-block} the distance between blocks A and B
can be computed with the following formula:

\begin{equation}
d(A, B) = w d_{0}(A, B) + (1 - w) d_{1}(A, B)
\qquad\parbox{4.0cm}{\footnotesize$\begin{aligned} 
  w &= \text{ weighted factor }
  \end{aligned}$}
\label{eqn: distance-block}
\end{equation}

The formation flight module implemented for this thesis will integrate with 
a module of collision avoidance based on ORCA\abbrev{ORCA}{Optical Recognition
Collision Avoidance}.

Millington proposes a set of algorithms for movement in \cite{ai-games}.
In his book, he divides these kind of algorithms based on variable of speed and
acceleration. The categories are:

\begin{description}
  \item [Stationary and Running] where the output is represented simply by the 
  direction of movement. The movement imposed by this type of algorithm is called
  \textbf{kinematic movement} and it is not influenced by acceleration or
  deceleration.
  \item [Dynamic] where the output is represented by accelerations or forces
  that are meant to change the velocity of the agent.
\end{description}

If the environment is a 2D space, the output from this algorithms would
  be represented by one (or both) of the two following values:
\begin{inparaenum}[\itshape a\upshape)]
\item clockwise angle in radians from the positive z-axis (the vertical axis 
being the y-axis); and
\item acceleration needed to change velocity
\end{inparaenum}.
The mathematical model necessary used in 3D could be very complicated, thus 
Millington proposes in \cite{ai-games}, \textit{Chapter 3. Movement} a hybrid 
coordinate system with 4 degrees of freedom called $\mathbf{2\frac{1}{2}}$
\textbf{Dimensions}. In most 3D simulations these system use sufficient because 
an agent is always pulled down by the gravity. Even in the cases where a character
is looking up or down, the movement direction is not influenced by the viewing 
direction. For computational purposes it is usually more convenient to represent
an orientation as a vector instead of a scalar. The transformation can be computed
with the following formula (assuming a right-handed direction):

\begin{equation}
\overrightarrow {w_{v}} = 
  \begin{bmatrix}
\sin w_{s} \\ \cos w_{s}
  \end{bmatrix}
\qquad\parbox{4.0cm}{\footnotesize$\begin{aligned} 
  w_{s} &= \text{ orientation as scalar}
  \\[-1.0ex] \overrightarrow {w_{v}} &= \text{ orientation as vector}
  \end{aligned}$}
\label{eqn:scalar-to-vector}
\end{equation}

Millington proposes a set of algorithms for achieving kinematic movement by 
using only static data (position and orientation without velocity). The algorithms
are described below \cite{ai-games}:

\begin{description}
\item [Seek] \hfill \\ Based on static data about the source and destination, the direction
between them is computed and movement along that line is required. If the source
is static, moving at full speed could cause the agent to pass the destination
and move back and forward reaching a state of \textbf{Stable Equilibria}. To 
avoid this, it could be considered that the target has been reached if the 
agent is at a distance from the target that is smaller than a predefined
radius.
\item [Wandering] \hfill \\ The agent always moves at full speed in the direction
of the current orientation and at each step the orientation could be
altered by a small amount using a binomial random function ( computes values between
-1 and 1 with a higher probability for 0.
\end{description}

For this thesis a \textbf{Wandering behavior} would not be useful, but the 
\textbf{Seek behavior} is used for obtaining a \textit{follow the leader} movement.

Millington also proposes a set of steering behavior based on outputting accelerations:
\begin{description}
\item {Variable matching} One agent tries to mimic the kinematic of another agent.
\item {Seek and Flee} One agent tries to mimic the position of the target agent
or move further from the target, being similar to the \textbf{kinematic Seek}
\item {Arrive} Is an improvement from \textbf{Seek}, but here the agent slows 
down when is close to the target.
\item {Face} Here the agent first calculates the target orientation and then
tries to head in the direction of the target's next position.
\end{description}

For movement in 3 dimension, Millington states that the algorithms described by
him have to be adapted by using quaternions.

In this thesis I used the \textit{Variable Matching} behavior for flying in the
same direction and \textit{Seek and Flee} for entering formation.